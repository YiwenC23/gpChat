# Zulip AI Agents Integration

This project integrates Zulip's Welcome Bot frontend with Ollama AI models to provide intelligent chat assistant functionality.

## Features

### ðŸš€ Core Features
- **AI-driven Welcome Bot**: Welcome Bot now uses Ollama local AI models to generate responses
- **Intelligent Chat Interface**: Provides direct chat functionality with AI agents
- **Model Management**: View and manage available AI models
- **Health Status Monitoring**: Real-time monitoring of Ollama service status

### ðŸ¤– AI Agent Features
- **Multi-model Support**: Supports multiple Ollama models (llama3.1:8b, nomic-embed-text:v1.5, etc.)
- **Context Awareness**: AI can understand Zulip's organizational structure and user information
- **Intelligent Responses**: Provides relevant Zulip functionality explanations based on user questions
- **Error Handling**: Automatically falls back to original response logic when AI service is unavailable

## Installation and Setup

### 1. System Requirements
- Zulip development environment set up
- Ollama installed and running
- At least 8GB RAM (16GB+ recommended)

### 2. Ollama Installation
```bash
# Install Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Start Ollama service
ollama serve

# Download required models
ollama pull llama3.1:8b
ollama pull nomic-embed-text:v1.5
```

### 3. Configure Zulip
Ensure the following settings in `zproject/settings.py`:

```python
# AI Agents Configuration
AI_AGENTS_ENABLED = True
OLLAMA_BASE_URL = "http://localhost:11434"
AI_AGENTS_DEFAULT_MODEL = "llama3.1:8b"
AI_AGENTS_EMBEDDING_MODEL = "nomic-embed-text:v1.5"
```

## Usage

### 1. Welcome Bot Conversation
- New users automatically receive AI-driven welcome messages after registration
- Users can have natural language conversations with Welcome Bot
- AI provides relevant Zulip functionality explanations based on user questions

### 2. AI Chat Interface
- Click "AI Chat" button in settings page
- Select the AI model you want to use
- Input questions and receive AI responses

### 3. Status Monitoring
- View AI service status in settings page
- Monitor available models and service health

## API Endpoints

### AI Chat
```
POST /json/ai/chat
{
    "message": "User message",
    "context": "Optional context",
    "agent_type": "general",
    "model": "Optional model name"
}
```

### Health Check
```
GET /json/ai/health
```

### Model List
```
GET /json/ai/models
```

## File Structure

```
zerver/
â”œâ”€â”€ lib/
â”‚   â””â”€â”€ ai_agents.py          # AI agents core logic
â”œâ”€â”€ views/
â”‚   â””â”€â”€ ai_agents.py          # AI agents API endpoints
â”œâ”€â”€ models/
â”‚   â””â”€â”€ ai_agents.py          # AI agents data models
â””â”€â”€ tests/
    â””â”€â”€ test_ai_agents_integration.py  # Test scripts

web/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ai_agents.ts          # Frontend AI agents module
â”‚   â””â”€â”€ settings_ai_agents.ts # AI agents settings page
â””â”€â”€ styles/
    â””â”€â”€ ai_agents.css         # AI agents styles
```

## Testing

### Run Tests
```bash
# Simple test
python test_ai_simple.py

# Django shell test
python manage.py shell
>>> exec(open('zerver/tests/test_ai_agents_integration.py').read())
```

### Test Content
- Ollama connection test
- AI model list test
- Chat functionality test
- Welcome Bot integration test

## Troubleshooting

### Common Issues

1. **Ollama Connection Failed**
   ```bash
   # Check Ollama service status
   systemctl status ollama
   
   # Restart Ollama service
   sudo systemctl restart ollama
   ```

2. **Model Download Failed**
   ```bash
   # Manually download models
   ollama pull llama3.1:8b
   ollama pull nomic-embed-text:v1.5
   ```

3. **Insufficient Memory**
   - Ensure system has enough RAM (at least 8GB)
   - Consider using smaller models

4. **Slow AI Responses**
   - Check Ollama service performance
   - Consider using faster hardware or smaller models

### Log Viewing
```bash
# View Zulip logs
tail -f /var/log/zulip/server.log

# View Ollama logs
journalctl -u ollama -f
```

## Development Guide

### Adding New Models
1. Download new model to Ollama
2. Configure new model in `zproject/settings.py`
3. Update frontend model selector

### Customizing AI Responses
Modify the `send_welcome_bot_response` function in `zerver/lib/onboarding.py` to adjust AI response logic.

### Extending Functionality
- Add more AI agent types
- Implement conversation history
- Add model performance monitoring
- Implement multi-language support

## Contributing

Welcome to submit Issues and Pull Requests to improve this functionality!

## License

This project follows Zulip's open source license. 